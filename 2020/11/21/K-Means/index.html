<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#003399">
<meta name="generator" content="Hexo 5.2.0">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#003399">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Times+New+Roman:300,300italic,400,400italic,700,700italic|PT+Mono:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.1/css/all.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/animate.css@3.1.1/animate.min.css">
  <link rel="stylesheet" href="//cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.css">
  <script src="//cdn.jsdelivr.net/npm/nprogress@0.2.0/nprogress.js"></script>

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"knightpanda.github.io","root":"/","images":"/images","scheme":"Gemini","version":"8.0.2","exturl":false,"sidebar":{"position":"right","display":"hide","padding":18,"offset":12},"copycode":"true#false","bookmark":{"enable":true,"color":"#FF0099","save":"manual"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"}};
  </script>

  <meta name="description" content="K均值聚类算法Clustering聚类  聚类是一种无监督学习，它将相似的对象归到同一个簇中，簇内的对象越相似，聚类效果越好，k-均值 K-means聚类算法，可以发现k个不同的簇每个簇的中心采用簇中所含值的均值计算 聚类和分类的最大区别是，分类目标事先已知，而聚类则不一样，因为其产生的结果与分类相同，而是只是类别没有预先定义，聚类有时候被称为无监督分类unsupervised classific">
<meta property="og:type" content="article">
<meta property="og:title" content="K均值聚类算法">
<meta property="og:url" content="https://knightpanda.github.io/2020/11/21/K-Means/index.html">
<meta property="og:site_name" content="不木的番茄">
<meta property="og:description" content="K均值聚类算法Clustering聚类  聚类是一种无监督学习，它将相似的对象归到同一个簇中，簇内的对象越相似，聚类效果越好，k-均值 K-means聚类算法，可以发现k个不同的簇每个簇的中心采用簇中所含值的均值计算 聚类和分类的最大区别是，分类目标事先已知，而聚类则不一样，因为其产生的结果与分类相同，而是只是类别没有预先定义，聚类有时候被称为无监督分类unsupervised classific">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://knightpanda.github.io/2020/11/21/K-Means/image-20201119215035439.png">
<meta property="og:image" content="https://knightpanda.github.io/2020/11/21/K-Means/image-20201119214323305-1605969986831.png">
<meta property="og:image" content="https://knightpanda.github.io/2020/11/21/K-Means/image-20201120093653154-1605969986832.png">
<meta property="og:image" content="https://knightpanda.github.io/2020/11/21/K-Means/image-20201120101405055-1605969986832.png">
<meta property="og:image" content="https://knightpanda.github.io/2020/11/21/K-Means/image-20201120181946385.png">
<meta property="article:published_time" content="2020-11-21T14:35:11.000Z">
<meta property="article:modified_time" content="2020-11-21T14:49:27.300Z">
<meta property="article:author" content="KnightPanda">
<meta property="article:tag" content="ML">
<meta property="article:tag" content="无监督学习">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://knightpanda.github.io/2020/11/21/K-Means/image-20201119215035439.png">


<link rel="canonical" href="https://knightpanda.github.io/2020/11/21/K-Means/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>K均值聚类算法 | 不木的番茄</title>
  






  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">不木的番茄</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">6</span></a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">4</span></a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">13</span></a>

  </li>
  </ul>
</nav>




</div>
        
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <section class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#K%E5%9D%87%E5%80%BC%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95"><span class="nav-number">1.</span> <span class="nav-text">K均值聚类算法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#10-1-K-%E5%9D%87%E5%80%BC%E8%81%9A%E7%B1%BB%E7%AE%97%E6%B3%95"><span class="nav-number">1.1.</span> <span class="nav-text">10.1    K-均值聚类算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#10-2-%E4%BD%BF%E7%94%A8%E5%90%8E%E5%A4%84%E7%90%86%E6%9D%A5%E6%8F%90%E9%AB%98%E8%81%9A%E7%B1%BB%E6%80%A7%E8%83%BD"><span class="nav-number">1.2.</span> <span class="nav-text">10.2 使用后处理来提高聚类性能</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#10-3-%E4%BA%8C%E5%88%86-K-%E5%9D%87%E5%80%BC%E7%AE%97%E6%B3%95"><span class="nav-number">1.3.</span> <span class="nav-text">10.3 二分 K-均值算法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#10-4-%E7%A4%BA%E4%BE%8B-%E5%AF%B9%E5%9C%B0%E5%9B%BE%E4%B8%8A%E7%9A%84%E7%82%B9%E8%BF%9B%E8%A1%8C%E8%81%9A%E7%B1%BB"><span class="nav-number">1.3.1.</span> <span class="nav-text">10.4 示例 对地图上的点进行聚类</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#%E5%AF%B9%E5%9C%B0%E7%90%83%E5%9D%90%E6%A0%87%E8%81%9A%E7%B1%BB"><span class="nav-number">1.3.2.</span> <span class="nav-text">对地球坐标聚类</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#10-5-%E6%9C%AC%E7%AB%A0%E5%B0%8F%E7%BB%93"><span class="nav-number">1.4.</span> <span class="nav-text">10.5 本章小结</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BD%BF%E7%94%A8sklearn"><span class="nav-number">1.5.</span> <span class="nav-text">使用sklearn</span></a></li></ol></li></ol></div>
        </section>
        <!--/noindex-->

        <section class="site-overview-wrap sidebar-panel">
          <div class="site-author site-overview-item animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="KnightPanda"
      src="/images/avatar.jpg#/images/avatar.gif">
  <p class="site-author-name" itemprop="name">KnightPanda</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap site-overview-item animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">13</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">4</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">6</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="links-of-author site-overview-item animated">
      <span class="links-of-author-item">
        <a href="https://github.com/KnightPanda" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;KnightPanda" rel="noopener" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:xuwenkai13@gmail.com" title="E-Mail → mailto:xuwenkai13@gmail.com" rel="noopener" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a>
      </span>
  </div>



        </section>
      </div>
        <div class="back-to-top animated">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>
    </div>
  </aside>
  <div class="sidebar-dimmer"></div>


    </header>

    
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

  <a href="https://github.com/KnightPanda" class="github-corner" title="Follow me on GitHub" aria-label="Follow me on GitHub" rel="noopener" target="_blank"><svg width="80" height="80" viewBox="0 0 250 250" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


    <div class="main-inner post posts-expand">
      

      

  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://knightpanda.github.io/2020/11/21/K-Means/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpg#/images/avatar.gif">
      <meta itemprop="name" content="KnightPanda">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="不木的番茄">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          K均值聚类算法
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>
      

      <time title="创建时间：2020-11-21 22:35:11 / 修改时间：22:49:27" itemprop="dateCreated datePublished" datetime="2020-11-21T22:35:11+08:00">2020-11-21</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/" itemprop="url" rel="index"><span itemprop="name">机器学习实战</span></a>
        </span>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
        <h1 id="K均值聚类算法"><a href="#K均值聚类算法" class="headerlink" title="K均值聚类算法"></a>K均值聚类算法</h1><p><strong>Clustering聚类</strong></p>
<blockquote>
<p>聚类是一种无监督学习，它将相似的对象归到同一个簇中，簇内的对象越相似，聚类效果越好，k-均值 <code>K-means</code>聚类算法，可以发现k个不同的簇每个簇的中心采用簇中所含值的均值计算</p>
<p>聚类和分类的最大区别是，分类目标事先已知，而聚类则不一样，因为其产生的结果与分类相同，而是只是类别没有预先定义，聚类有时候被称为无监督分类<code>unsupervised classification</code></p>
<p>聚类分析试图将相似对象归入同一簇，将不相似的对象归到不同簇</p>
<p>相似取决于相似度计算方法</p>
</blockquote>
<h2 id="10-1-K-均值聚类算法"><a href="#10-1-K-均值聚类算法" class="headerlink" title="10.1    K-均值聚类算法"></a>10.1    K-均值聚类算法</h2><p>优点：易实现</p>
<p>缺点:可能收敛到局部最小值，在大规模数据上收敛比较慢</p>
<p>数据：数值型数据</p>
<p>“””</p>
<p>算法过程描述：<br>创建k个点作为质心<br>当任意一个点的簇分配结果发生改变时<br>    对数据中的每个样本点<br>        对每个质心<br>            计算质心到样本点的距离<br>        将该样本点划分到距离其最近的簇<br>    对每个簇计算所有样本的均值作为质心<br>“””</p>
<blockquote>
<p>相关说明：</p>
<p>簇分配结果矩阵<code>clusterAssment</code>包含 记录簇索引值 列存储误差（点到簇质心的距离)</p>
<p><code>clusterChanged</code>标志变量 True 则继续迭代</p>
<p>如果任意一点的簇分配结果发生改变，则更新标志变量</p>
</blockquote>
<p><img src="image-20201119215035439.png" alt="image-20201119215035439"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time : 2020/11/18 16:05 </span></span><br><span class="line"><span class="comment"># @Author : xulei </span></span><br><span class="line"><span class="comment"># @File : try_1.py</span></span><br><span class="line"></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">算法过程描述：</span></span><br><span class="line"><span class="string">创建k个点作为质心</span></span><br><span class="line"><span class="string">当任意一个点的簇分配结果发生改变时</span></span><br><span class="line"><span class="string">    对数据中的每个样本点</span></span><br><span class="line"><span class="string">        对每个质心</span></span><br><span class="line"><span class="string">            计算质心到样本点的距离</span></span><br><span class="line"><span class="string">        将该样本点划分到距离其最近的簇</span></span><br><span class="line"><span class="string">    对每个簇计算所有样本的均值作为质心</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="comment">#读入文件</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span>(<span class="params">filename</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param filename: 文件名</span></span><br><span class="line"><span class="string">    :return: 数据矩阵</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    dataMat = []</span><br><span class="line">    fr = <span class="built_in">open</span>(filename)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines():</span><br><span class="line">        curLine = line.strip().split(<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">        fltLine =<span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">float</span>,curLine))<span class="comment">#映射改变数据类型</span></span><br><span class="line">        dataMat.append(fltLine)</span><br><span class="line">    <span class="keyword">return</span> dataMat</span><br><span class="line"></span><br><span class="line"><span class="comment">#距离计算（欧几里得距离）</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distEclud</span>(<span class="params">vecA,vecB</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param vecA: 数据向量A</span></span><br><span class="line"><span class="string">    :param vecB: 数据向量B</span></span><br><span class="line"><span class="string">    :return: 两向量之间的欧几里得距离</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">return</span> np.sqrt(np.<span class="built_in">sum</span>(np.power(vecA-vecB,<span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">#返回初始化得到的k个质心向量</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">randCent</span>(<span class="params">dataSet,k</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">    随机初始化k个质心（其中质心满足边界条件 ）</span></span><br><span class="line"><span class="string">    :param dataSet: 输入训练集</span></span><br><span class="line"><span class="string">    :param k: 质心个数</span></span><br><span class="line"><span class="string">    :return: 初始化的k个质心向量</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    n = np.shape(dataSet)[<span class="number">1</span>]<span class="comment">#数据样本的维度</span></span><br><span class="line">    centroids = np.mat(np.zeros((k,n)))<span class="comment">#初始化（k,n）的全零矩阵</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        MinJ = np.<span class="built_in">min</span>(dataSet[:,j])</span><br><span class="line">        MaxJ = np.<span class="built_in">max</span>(dataSet[:,j])</span><br><span class="line">        rangeJ = <span class="built_in">float</span>(MaxJ-MinJ)<span class="comment">#得到这列数据的范围</span></span><br><span class="line">        centroids[:,j]=MinJ+rangeJ*np.random.rand(k,<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> centroids</span><br><span class="line"></span><br><span class="line"><span class="comment">#k-means聚类算法</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kMeans</span>(<span class="params">dataSet,k,distMeas=distEclud,createCent=randCent</span>):</span></span><br><span class="line">    <span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    :param dataSet: 数据集</span></span><br><span class="line"><span class="string">    :param k: 质心个数</span></span><br><span class="line"><span class="string">    :param distMeas: 距离计算的方法</span></span><br><span class="line"><span class="string">    :param createCent: 获取k个质心的方法</span></span><br><span class="line"><span class="string">    :return: centioids k个聚类的聚类结果 clusterAssment 聚类误差</span></span><br><span class="line"><span class="string">    &quot;&quot;&quot;</span></span><br><span class="line">    m = np.shape(dataSet)[<span class="number">0</span>]<span class="comment">#获得样本集数量</span></span><br><span class="line">    clusterAssment = np.mat(np.zeros((m,<span class="number">2</span>)))<span class="comment">#初始m,2的全零矩阵</span></span><br><span class="line">    <span class="comment">#用于存储类别以及距离</span></span><br><span class="line">    centroids = createCent(dataSet,k)<span class="comment">#初始化k个质心向量</span></span><br><span class="line">    clusterChanged = <span class="literal">True</span><span class="comment">#聚类结果发生变化</span></span><br><span class="line">    <span class="comment">#只要聚类结果一直发生变化，就一直执行聚类算法，直至聚类结果不发生变化</span></span><br><span class="line">    <span class="keyword">while</span> clusterChanged:</span><br><span class="line">        clusterChanged = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">            <span class="comment">#初始化最小距离为正无穷，最小距离对应的索引为-1</span></span><br><span class="line">            minDist=<span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)</span><br><span class="line">            minIndex=<span class="number">-1</span></span><br><span class="line">            <span class="comment">#循环k个类的质心</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">                <span class="comment">#计算数据点到质心的欧式距离</span></span><br><span class="line">                disJI = distMeas(centroids[j,:],dataSet[i,:])</span><br><span class="line">                <span class="keyword">if</span> disJI &lt;minDist:</span><br><span class="line">                    minDist = disJI</span><br><span class="line">                    minIndex = j</span><br><span class="line">            <span class="keyword">if</span> clusterAssment[i,<span class="number">0</span>] != minIndex:</span><br><span class="line">                clusterChanged = <span class="literal">True</span></span><br><span class="line">        <span class="comment">#更新当前样本的聚类结果和平方误差</span></span><br><span class="line">            clusterAssment[i,:] = minIndex, minDist**<span class="number">2</span></span><br><span class="line">        <span class="comment">#遍历每一个质心</span></span><br><span class="line">        <span class="comment">#.A实现矩阵转数组</span></span><br><span class="line">        <span class="keyword">for</span> cent <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">            <span class="comment">#将数据集中属于cent类别的样本筛选出来</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            ptsInClust = dataSet[np.nonzero(clusterAssment[:, <span class="number">0</span>].A == cent)[<span class="number">0</span>]]</span><br><span class="line">            <span class="comment">#求列均值 axis=0</span></span><br><span class="line">            centroids[cent, :] = np.mean(ptsInClust, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> centroids,clusterAssment</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotDataSet</span>(<span class="params">filename</span>):</span></span><br><span class="line">    <span class="comment"># 导入数据</span></span><br><span class="line">    datMat = np.mat(loadDataSet(filename))</span><br><span class="line">    <span class="comment"># 进行k-means算法其中k为4</span></span><br><span class="line">    myCentroids, clustAssing = kMeans(datMat, <span class="number">4</span>)</span><br><span class="line">    clustAssing = clustAssing.tolist()</span><br><span class="line">    myCentroids = myCentroids.tolist()</span><br><span class="line">    xcord = [[], [], [], []]</span><br><span class="line">    ycord = [[], [], [], []]</span><br><span class="line">    datMat = datMat.tolist()</span><br><span class="line">    m = <span class="built_in">len</span>(clustAssing)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">int</span>(clustAssing[i][<span class="number">0</span>]) == <span class="number">0</span>:</span><br><span class="line">            xcord[<span class="number">0</span>].append(datMat[i][<span class="number">0</span>])</span><br><span class="line">            ycord[<span class="number">0</span>].append(datMat[i][<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">int</span>(clustAssing[i][<span class="number">0</span>]) == <span class="number">1</span>:</span><br><span class="line">            xcord[<span class="number">1</span>].append(datMat[i][<span class="number">0</span>])</span><br><span class="line">            ycord[<span class="number">1</span>].append(datMat[i][<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">int</span>(clustAssing[i][<span class="number">0</span>]) == <span class="number">2</span>:</span><br><span class="line">            xcord[<span class="number">2</span>].append(datMat[i][<span class="number">0</span>])</span><br><span class="line">            ycord[<span class="number">2</span>].append(datMat[i][<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">elif</span> <span class="built_in">int</span>(clustAssing[i][<span class="number">0</span>]) == <span class="number">3</span>:</span><br><span class="line">            xcord[<span class="number">3</span>].append(datMat[i][<span class="number">0</span>])</span><br><span class="line">            ycord[<span class="number">3</span>].append(datMat[i][<span class="number">1</span>])</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line">    <span class="comment"># 绘制样本点</span></span><br><span class="line">    ax.scatter(xcord[<span class="number">0</span>], ycord[<span class="number">0</span>], s=<span class="number">20</span>, c=<span class="string">&#x27;b&#x27;</span>, marker=<span class="string">&#x27;*&#x27;</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    ax.scatter(xcord[<span class="number">1</span>], ycord[<span class="number">1</span>], s=<span class="number">20</span>, c=<span class="string">&#x27;r&#x27;</span>, marker=<span class="string">&#x27;D&#x27;</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    ax.scatter(xcord[<span class="number">2</span>], ycord[<span class="number">2</span>], s=<span class="number">20</span>, c=<span class="string">&#x27;c&#x27;</span>, marker=<span class="string">&#x27;&gt;&#x27;</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    ax.scatter(xcord[<span class="number">3</span>], ycord[<span class="number">3</span>], s=<span class="number">20</span>, c=<span class="string">&#x27;y&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    <span class="comment"># 绘制质心</span></span><br><span class="line">    ax.scatter(myCentroids[<span class="number">0</span>][<span class="number">0</span>], myCentroids[<span class="number">0</span>][<span class="number">1</span>], s=<span class="number">100</span>, c=<span class="string">&#x27;k&#x27;</span>, marker=<span class="string">&#x27;+&#x27;</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    ax.scatter(myCentroids[<span class="number">1</span>][<span class="number">0</span>], myCentroids[<span class="number">1</span>][<span class="number">1</span>], s=<span class="number">100</span>, c=<span class="string">&#x27;k&#x27;</span>, marker=<span class="string">&#x27;+&#x27;</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    ax.scatter(myCentroids[<span class="number">2</span>][<span class="number">0</span>], myCentroids[<span class="number">2</span>][<span class="number">1</span>], s=<span class="number">100</span>, c=<span class="string">&#x27;k&#x27;</span>, marker=<span class="string">&#x27;+&#x27;</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    ax.scatter(myCentroids[<span class="number">3</span>][<span class="number">0</span>], myCentroids[<span class="number">3</span>][<span class="number">1</span>], s=<span class="number">100</span>, c=<span class="string">&#x27;k&#x27;</span>, marker=<span class="string">&#x27;+&#x27;</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    plt.title(<span class="string">&#x27;DataSet&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;X&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    plotDataSet(<span class="string">&#x27;testSet.txt&#x27;</span>)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="10-2-使用后处理来提高聚类性能"><a href="#10-2-使用后处理来提高聚类性能" class="headerlink" title="10.2 使用后处理来提高聚类性能"></a>10.2 使用后处理来提高聚类性能</h2><p><img src="image-20201119214323305-1605969986831.png" alt="image-20201119214323305"></p>
<ol>
<li><p>K-均值剧烈中簇的数量k是一个用户预先定义的参数，那么用户如何才能知道k的选择是正确的？如何才能知道生成的簇是比较好的呢？</p>
</li>
<li><p>k-均值算法收敛到局部最小，而不是全局最小</p>
</li>
<li><p>一种用于度量聚类效果的指标是SSE 误差平方和 <code>Sum of Squared Error</code> SSE值越小意味着数据点越接近它们的质心，也就是聚类效果越好</p>
</li>
<li><p>误差取了平方，因此更加重视那些远离中心的点 </p>
</li>
<li><p>一种降低SSE的值的方法是增加簇的数量，但这违背了聚类的目标，聚类的目标是在保持簇数目不变的情况下提高簇的质量</p>
</li>
<li><p>如何对生成的簇进行后处理</p>
<ul>
<li>一种方法是将具有最大SSE值的簇划分成两个簇，具体实现可以将最大簇包含的点过滤出来并在这些点上运行K-均值算法，其中k设为2</li>
<li>为了保持簇总数不变，可以将某两个簇进行合并。</li>
<li>合并方式：<ul>
<li>合并最近的质心</li>
<li>合并两个使得SSE增幅最小的质心</li>
</ul>
</li>
</ul>
</li>
</ol>
<h2 id="10-3-二分-K-均值算法"><a href="#10-3-二分-K-均值算法" class="headerlink" title="10.3 二分 K-均值算法"></a>10.3 二分 K-均值算法</h2><blockquote>
<p>为了克服K-均值算法收敛局部最小的问题，有人提出了二分K-均值的算法</p>
<p>该算法先将所有的点作为一个簇，然后将该簇一分为二，之后选择其中一个簇继续划分，选择哪一个簇进行划分取决于对其划分是否可以最大程度降低SSE值。上述基于SSE的划分过程不断重复，直至得到用户指定的簇数目为止</p>
</blockquote>
<p>“””</p>
<p>将所有点看成一个簇</p>
<p>当簇数目小于k时</p>
<p>对每个簇</p>
<p>​    计算总误差</p>
<p>​    在给定的簇上面进行K-均值聚类（k=2）</p>
<p>​    计算将该簇一分为二后的总误差</p>
<p>选择使得误差最小的那个簇进行划分操作</p>
<p>“””</p>
<p>另一个做法就是选择SSE最大的簇进行划分</p>
<p><img src="image-20201120093653154-1605969986832.png" alt="image-20201120093653154"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time : 2020/11/19 21:57 </span></span><br><span class="line"><span class="comment"># @Author : xulei </span></span><br><span class="line"><span class="comment"># @File : try_2.py</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadDataSet</span>(<span class="params">filename</span>):</span>  <span class="comment"># 载入数据集</span></span><br><span class="line">    dataMat = []</span><br><span class="line">    fr = <span class="built_in">open</span>(filename)</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> fr.readlines():</span><br><span class="line">        curline = line.strip().split(<span class="string">&#x27;\t&#x27;</span>)  <span class="comment"># strip ()为空默认删除空格</span></span><br><span class="line">        fltline = <span class="built_in">list</span>(<span class="built_in">map</span>(<span class="built_in">float</span>, curline))</span><br><span class="line">        dataMat.append(fltline)</span><br><span class="line">    <span class="keyword">return</span> dataMat</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># 计算欧式距离</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distEclud</span>(<span class="params">vecA, vecB</span>):</span></span><br><span class="line">    <span class="keyword">return</span> np.sqrt(np.<span class="built_in">sum</span>(np.power(vecA - vecB, <span class="number">2</span>)))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">randCent</span>(<span class="params">dataSet, k</span>):</span></span><br><span class="line">    n = np.shape(dataSet)[<span class="number">1</span>]  <span class="comment"># 得到样本的维度</span></span><br><span class="line">    centroids = np.mat(np.zeros((k, n)))</span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        MinJ = np.<span class="built_in">min</span>(dataSet[:, j])</span><br><span class="line">        Maxj = np.<span class="built_in">max</span>(dataSet[:, j])</span><br><span class="line">        _range = <span class="built_in">float</span>(Maxj - MinJ)</span><br><span class="line">        centroids[:, j] = MinJ + _range * np.random.rand(k, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">return</span> centroids  <span class="comment"># 初始化得到K个质心向量</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">Kmeans</span>(<span class="params">dataSet, k, disMeas=distEclud, createCent=randCent</span>):</span></span><br><span class="line">    m = np.shape(dataSet)[<span class="number">0</span>]  <span class="comment"># 得到样本个数</span></span><br><span class="line">    clusterAssment = np.mat(np.zeros((m, <span class="number">2</span>)))</span><br><span class="line">    centroids = createCent(dataSet, k)</span><br><span class="line">    clusterchanged = <span class="literal">True</span></span><br><span class="line">    <span class="keyword">while</span> clusterchanged:</span><br><span class="line">        clusterchanged = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):  <span class="comment"># 遍历每一样本集</span></span><br><span class="line">            minDist = <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)</span><br><span class="line">            minIndex = <span class="number">-1</span></span><br><span class="line">            <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">                disJI = disMeas(centroids[j, :], dataSet[i, :])</span><br><span class="line">                <span class="keyword">if</span> disJI &lt; minDist:</span><br><span class="line">                    minDist = disJI</span><br><span class="line">                    minIndex = j</span><br><span class="line">            <span class="keyword">if</span> clusterAssment[i, <span class="number">0</span>] != minIndex:</span><br><span class="line">                clusterchanged = <span class="literal">True</span></span><br><span class="line">            clusterAssment[i, :] = minIndex, minDist ** <span class="number">2</span></span><br><span class="line">        <span class="keyword">for</span> cent <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">            ptsInClust = dataSet[np.nonzero(clusterAssment[:, <span class="number">0</span>].A == cent)[<span class="number">0</span>]]</span><br><span class="line">            centroids[cent, :] = np.mean(ptsInClust, axis=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">return</span> centroids, clusterAssment</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">biKmeans</span>(<span class="params">dataSet, k, disMeas=distEclud</span>):</span></span><br><span class="line">    <span class="comment"># 获得数据集的样本数</span></span><br><span class="line">    m = np.shape(dataSet)[<span class="number">0</span>]</span><br><span class="line">    clusterAssment = np.mat(np.zeros((m, <span class="number">2</span>)))</span><br><span class="line">    centroid0 = np.mean(dataSet, axis=<span class="number">0</span>).tolist()[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 获取数据集每一列的均值，组成一个列表</span></span><br><span class="line">    centList = [centroid0]</span><br><span class="line">    <span class="comment"># 遍历每个数据集样本</span></span><br><span class="line">    <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">        clusterAssment[j, <span class="number">1</span>] = disMeas(np.mat(centroid0), dataSet[j, :]) ** <span class="number">2</span></span><br><span class="line">    <span class="comment"># 循环至二分k-Means值达到k类为止</span></span><br><span class="line">    <span class="keyword">while</span> (<span class="built_in">len</span>(centList) &lt; k):</span><br><span class="line">        <span class="comment"># 当前最小平方误差为正无穷</span></span><br><span class="line">        lowerSSE = <span class="built_in">float</span>(<span class="string">&#x27;inf&#x27;</span>)</span><br><span class="line">        <span class="comment"># 遍历当前每个聚类</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(centList)):</span><br><span class="line">            <span class="comment"># 通过数组过滤出属于第i类的数据集合</span></span><br><span class="line">            ptsInCurrCluster = dataSet[np.nonzero(clusterAssment[:, <span class="number">0</span>].A == i)[<span class="number">0</span>], :]</span><br><span class="line">            <span class="comment"># 对该类利用二分k-means算法划分，返回划分后的结果以及误差</span></span><br><span class="line">            centroidMat, splitClustAss = Kmeans(ptsInCurrCluster, <span class="number">2</span>, disMeas)</span><br><span class="line">            <span class="comment"># 计算该类划分后两个类的误差平方和</span></span><br><span class="line">            sseSplit = np.<span class="built_in">sum</span>(splitClustAss[:, <span class="number">1</span>])</span><br><span class="line">            <span class="comment"># 计算数据集中不属于该类的误差平方和</span></span><br><span class="line">            sseNotSplit = np.<span class="built_in">sum</span>(clusterAssment[np.nonzero(clusterAssment[:, <span class="number">0</span>].A != i)[<span class="number">0</span>], <span class="number">1</span>])</span><br><span class="line">            <span class="comment"># 打印这两项的误差值</span></span><br><span class="line">            print(<span class="string">&#x27;ssesplit=%f,and ssenotsplit=%f&#x27;</span> % (sseSplit, sseNotSplit))</span><br><span class="line">            <span class="comment"># 划分第i类后总误差小于当前最小总误差</span></span><br><span class="line">            <span class="keyword">if</span> (sseNotSplit + sseSplit) &lt; lowerSSE:</span><br><span class="line">                <span class="comment"># 第i类作为本次划分类</span></span><br><span class="line">                bestCentToSplit = i</span><br><span class="line">                <span class="comment"># 划分后得到两质心向量</span></span><br><span class="line">                bestNewCents = centroidMat</span><br><span class="line">                <span class="comment"># 复制第i类中数据点聚类结果即为误差值</span></span><br><span class="line">                bestClustAss = splitClustAss.copy()</span><br><span class="line">                <span class="comment"># 更新当前最小误差</span></span><br><span class="line">                lowerSSE = sseSplit + sseNotSplit</span><br><span class="line">        bestClustAss[np.nonzero(bestClustAss[:, <span class="number">0</span>].A == <span class="number">1</span>)[<span class="number">0</span>], <span class="number">0</span>] = <span class="built_in">len</span>(centList)</span><br><span class="line">        bestClustAss[np.nonzero(bestClustAss[:, <span class="number">0</span>].A == <span class="number">0</span>)[<span class="number">0</span>], <span class="number">0</span>] = bestCentToSplit</span><br><span class="line">        print(<span class="string">&#x27;the bestCentToSplit is %d&#x27;</span> % bestCentToSplit)</span><br><span class="line">        print(<span class="string">&#x27;the len of bestClustAss is %d&#x27;</span> % <span class="built_in">len</span>(bestClustAss))</span><br><span class="line">        <span class="comment"># 更新质心向量</span></span><br><span class="line">        centList[bestCentToSplit] = bestNewCents[<span class="number">0</span>, :]</span><br><span class="line">        <span class="comment"># 添加新的类的质心向量</span></span><br><span class="line">        centList.append(bestNewCents[<span class="number">1</span>, :])</span><br><span class="line">        <span class="comment"># 更新clusterAssment列表中参与2-means聚类数据点变化后的分类编号，及数据该类的误差平方</span></span><br><span class="line">        clusterAssment[np.nonzero(clusterAssment[:, <span class="number">0</span>].A == bestCentToSplit)[<span class="number">0</span>], :] = bestClustAss</span><br><span class="line">        <span class="comment"># 返回聚类结果</span></span><br><span class="line">    <span class="keyword">return</span> centList, clusterAssment</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">plotDataSet</span>(<span class="params">filename, k</span>):</span></span><br><span class="line">    dataMat = np.mat(loadDataSet(filename))  <span class="comment"># 导入数据</span></span><br><span class="line">    centList, clusterAssment = biKmeans(dataMat, k)</span><br><span class="line">    clusterAssment = clusterAssment.tolist()</span><br><span class="line">    xcord = [[], [], []]</span><br><span class="line">    ycord = [[], [], []]</span><br><span class="line">    dataMat = dataMat.tolist()</span><br><span class="line">    m = <span class="built_in">len</span>(dataMat)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">        <span class="keyword">if</span> clusterAssment[i][<span class="number">0</span>] == <span class="number">0</span>:</span><br><span class="line">            xcord[<span class="number">0</span>].append(dataMat[i][<span class="number">0</span>])</span><br><span class="line">            ycord[<span class="number">0</span>].append(dataMat[i][<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">elif</span> clusterAssment[i][<span class="number">0</span>] == <span class="number">1</span>:</span><br><span class="line">            xcord[<span class="number">1</span>].append(dataMat[i][<span class="number">0</span>])</span><br><span class="line">            ycord[<span class="number">1</span>].append(dataMat[i][<span class="number">1</span>])</span><br><span class="line">        <span class="keyword">elif</span> clusterAssment[i][<span class="number">0</span>] == <span class="number">2</span>:</span><br><span class="line">            xcord[<span class="number">2</span>].append(dataMat[i][<span class="number">0</span>])</span><br><span class="line">            ycord[<span class="number">2</span>].append(dataMat[i][<span class="number">1</span>])</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    ax = fig.add_subplot(<span class="number">111</span>)</span><br><span class="line">    <span class="comment"># 绘制样本点</span></span><br><span class="line">    ax.scatter(xcord[<span class="number">0</span>], ycord[<span class="number">0</span>], s=<span class="number">20</span>, c=<span class="string">&#x27;b&#x27;</span>, marker=<span class="string">&#x27;*&#x27;</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    ax.scatter(xcord[<span class="number">1</span>], ycord[<span class="number">1</span>], s=<span class="number">20</span>, c=<span class="string">&#x27;r&#x27;</span>, marker=<span class="string">&#x27;d&#x27;</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    ax.scatter(xcord[<span class="number">2</span>], ycord[<span class="number">2</span>], s=<span class="number">20</span>, c=<span class="string">&#x27;y&#x27;</span>, marker=<span class="string">&#x27;x&#x27;</span>, alpha=<span class="number">.5</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">        ax.scatter(centList[i].tolist()[<span class="number">0</span>][<span class="number">0</span>], centList[i].tolist()[<span class="number">0</span>][<span class="number">1</span>], s=<span class="number">100</span>, c=<span class="string">&#x27;k&#x27;</span>, marker=<span class="string">&#x27;+&#x27;</span>, alpha=<span class="number">1.</span>)</span><br><span class="line"></span><br><span class="line">    plt.title(<span class="string">&#x27;DataSet&#x27;</span>)</span><br><span class="line">    plt.xlabel(<span class="string">&#x27;X&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    datMat = np.mat(loadDataSet(<span class="string">&#x27;testSet2.txt&#x27;</span>))</span><br><span class="line">    centList, myNewAssments = biKmeans(datMat, <span class="number">3</span>)</span><br><span class="line">    plotDataSet(<span class="string">&#x27;testSet2.txt&#x27;</span>, <span class="number">3</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<blockquote>
<p>while循环内不断对簇进行划分，直至得到我们想要的簇数目为止（可以 通过簇列表的值来得到簇数目。然后遍历所有簇来决定最佳的簇划分。需要比较划分前后的SSE。</p>
<p>首先设置最小的SSE为inf，然后遍历簇列表<code>centlist</code>。对每个簇内样本都可以看成一个数据集<code>ptsInCurrCluster</code>。将其输入<code>kMeans</code>内处理，其中k=2。K均值算法会生成两个质心簇，同时给出每个簇的误差值。这些误差与剩余数据的误差之和作为本次划分的误差。</p>
<p>由误差之和，决定要划分的簇</p>
<p>对划分簇中所有点的簇分配进行修改，当使用<code>kMeans</code>函数并且k=2时，会得到两个编号分别为0和1的簇，将簇编号修改为划分簇及新簇的编号</p>
<p>更新</p>
</blockquote>
<h3 id="10-4-示例-对地图上的点进行聚类"><a href="#10-4-示例-对地图上的点进行聚类" class="headerlink" title="10.4 示例 对地图上的点进行聚类"></a>10.4 示例 对地图上的点进行聚类</h3><blockquote>
<p>一晚上要去70个地方，你要决定一个将这些地方进行聚类的最佳策略，这样就可以安排交通工具抵达这些簇的中心，然后🚶‍到每个簇内地址</p>
<p>ps:这里我直接使用 <code>places.txt</code>使用经纬度</p>
</blockquote>
<h3 id="对地球坐标聚类"><a href="#对地球坐标聚类" class="headerlink" title="对地球坐标聚类"></a>对地球坐标聚类</h3><p>球面距离计算</p>
<p> <code>distSLC()</code>返回地球表面的两点之间的距离</p>
<p><code>clusterClubs()</code>将文本文件中的俱乐部进行聚类并画出结果</p>
<p>首先创建一幅图和一个矩形，然会使用矩形决定绘制图的哪一个部分，接下来构建一个标记形状的列表用于绘制散点图</p>
<p><code>imread()</code>基于一幅图像创建矩阵 <code>imshow()</code>绘制矩阵</p>
<p>标记类型从前面创建的<code>scatterMarkers</code>列表中得到。使用索引 <code>i % len(scatterMarkers)</code>来选择标记形状</p>
<p><img src="image-20201120101405055-1605969986832.png" alt="image-20201120101405055"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time : 2020/11/20 9:55 </span></span><br><span class="line"><span class="comment"># @Author : xulei </span></span><br><span class="line"><span class="comment"># @File : try_3.py</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> KMeans</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> math</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">distSLC</span>(<span class="params">vecA, vecB</span>):</span></span><br><span class="line">    a = math.sin(vecA[<span class="number">0</span>, <span class="number">1</span>] * np.pi / <span class="number">180</span>) * math.sin(vecB[<span class="number">0</span>, <span class="number">1</span>] * np.pi / <span class="number">180</span>)</span><br><span class="line">    b = math.cos(vecA[<span class="number">0</span>, <span class="number">1</span>] * np.pi / <span class="number">180</span>) * math.cos(vecB[<span class="number">0</span>, <span class="number">1</span>] * np.pi / <span class="number">180</span>) * math.cos(</span><br><span class="line">        np.pi * (vecB[<span class="number">0</span>, <span class="number">0</span>] - vecA[<span class="number">0</span>, <span class="number">0</span>]) / <span class="number">180</span>)</span><br><span class="line">    <span class="keyword">return</span> math.acos(a + b) * <span class="number">6371.0</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">clusterClubs</span>(<span class="params">numClust=<span class="number">5</span></span>):</span></span><br><span class="line">    datList = []</span><br><span class="line">    <span class="keyword">for</span> line <span class="keyword">in</span> <span class="built_in">open</span>(<span class="string">&#x27;places.txt&#x27;</span>).readlines():</span><br><span class="line">        curl = line.strip().split(<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">        datList.append([<span class="built_in">float</span>(curl[<span class="number">4</span>]), <span class="built_in">float</span>(curl[<span class="number">3</span>])])</span><br><span class="line">    datMat = np.mat(datList)</span><br><span class="line">    myCentroids, clustAssing = KMeans.biKmeans(datMat, numClust, distMeas=distSLC)</span><br><span class="line">    fig = plt.figure()</span><br><span class="line">    rect = [<span class="number">0.1</span>, <span class="number">0.1</span>, <span class="number">0.8</span>, <span class="number">0.8</span>]</span><br><span class="line">    scattermarker = [<span class="string">&#x27;s&#x27;</span>, <span class="string">&#x27;o&#x27;</span>, <span class="string">&#x27;^&#x27;</span>, <span class="string">&#x27;8&#x27;</span>, <span class="string">&#x27;p&#x27;</span>, <span class="string">&#x27;d&#x27;</span>, <span class="string">&#x27;v&#x27;</span>, <span class="string">&#x27;h&#x27;</span>, <span class="string">&#x27;&gt;&#x27;</span>, <span class="string">&#x27;&lt;&#x27;</span>]</span><br><span class="line">    axprops = <span class="built_in">dict</span>(xticks=[], yticks=[])</span><br><span class="line">    ax0 = fig.add_axes(rect, label=<span class="string">&#x27;ax0&#x27;</span>, **axprops)</span><br><span class="line">    imgP = plt.imread(<span class="string">&#x27;Portland.png&#x27;</span>)</span><br><span class="line">    ax0.imshow(imgP)</span><br><span class="line">    ax1 = fig.add_axes(rect, label=<span class="string">&#x27;ax1&#x27;</span>, frameon=<span class="literal">False</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(numClust):</span><br><span class="line">        ptsInCurrCluster = datMat[np.nonzero(clustAssing[:,<span class="number">0</span>].A == i)[<span class="number">0</span>], :]</span><br><span class="line">        mk = scattermarker[i % <span class="built_in">len</span>(scattermarker)]</span><br><span class="line">        ax1.scatter(ptsInCurrCluster[:, <span class="number">0</span>].flatten().A[<span class="number">0</span>],</span><br><span class="line">                    ptsInCurrCluster[:, <span class="number">1</span>].flatten().A[<span class="number">0</span>],</span><br><span class="line">                    marker=mk, s=<span class="number">50</span>)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(numClust):</span><br><span class="line">        ax1.scatter(myCentroids[i].tolist()[<span class="number">0</span>][<span class="number">0</span>], myCentroids[i].tolist()[<span class="number">0</span>][<span class="number">1</span>], s=<span class="number">300</span>, c=<span class="string">&#x27;k&#x27;</span>, marker=<span class="string">&#x27;+&#x27;</span>, alpha=<span class="number">.5</span>)</span><br><span class="line"></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    clusterClubs()</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h2 id="10-5-本章小结"><a href="#10-5-本章小结" class="headerlink" title="10.5 本章小结"></a>10.5 本章小结</h2><p>聚类是一种无监督学习。无监督学习是指事先不知道寻找的内容，也就是没有目标变量。聚类将数据点归到多个簇中，其中相似数据点处于同一簇，而不相似数据点处于不同簇，聚类可以使用多种方式计算相似度</p>
<p>K-均值算法，k是用户指定的要创建的簇的数目。k-均值聚类算法以k个随机质心开始 ，算法会计算每个点到质心的距离。每个点会被分配到距离其最近的簇的质心，然后基于新分配到簇的点更新簇质心。以上过程数次重复，直到质心不再改变。算法简单有效，但易受初始质心的影响。</p>
<p>为了更好的聚类效果，可以使用二分K-均值的聚类算法。首先将所有点作为一个簇，然后使用K-均值算法（k=2）对其划分。下次迭代选择有最大误差的簇进行划分。重复过程直至k个簇创建完成。</p>
<h2 id="使用sklearn"><a href="#使用sklearn" class="headerlink" title="使用sklearn"></a>使用sklearn</h2><p><img src="image-20201120181946385.png" alt="image-20201120181946385"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="comment"># @Time : 2020/11/20 18:06 </span></span><br><span class="line"><span class="comment"># @Author : xulei </span></span><br><span class="line"><span class="comment"># @File : try_4.py</span></span><br><span class="line"><span class="keyword">from</span> sklearn.datasets <span class="keyword">import</span> make_blobs<span class="comment">#聚类数据生成器</span></span><br><span class="line"><span class="keyword">from</span> sklearn.cluster <span class="keyword">import</span> KMeans</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    <span class="comment"># 生成聚类数据 150个样本，每个样本两个特征，一共聚为3簇，簇内标准差为0.5，所有样本数据随机排序，采用随机数种子</span></span><br><span class="line">    x,y=make_blobs(n_samples=<span class="number">150</span>,n_features=<span class="number">2</span>,centers=<span class="number">3</span>,cluster_std=<span class="number">0.5</span>,shuffle=<span class="literal">True</span>,random_state=<span class="number">0</span>)</span><br><span class="line">    <span class="comment">#绘制图像</span></span><br><span class="line">    plt.scatter(x[:,<span class="number">0</span>],x[:,<span class="number">1</span>],marker=<span class="string">&#x27;*&#x27;</span>,color=<span class="string">&#x27;r&#x27;</span>)</span><br><span class="line">    <span class="comment"># 聚为3个簇，从训练数据用k-means++寻找质心，初始样本中心的个数为10个，最大迭代次数为300，SSE为10^(-4)</span></span><br><span class="line">    km = KMeans(n_clusters=<span class="number">3</span>, init=<span class="string">&quot;k-means++&quot;</span>, n_init=<span class="number">10</span>, max_iter=<span class="number">300</span>, tol=<span class="number">1e-4</span>, random_state=<span class="number">0</span>)</span><br><span class="line">    <span class="comment"># 用K-means计算并且将X作为测试集分簇</span></span><br><span class="line">    y_km = km.fit_predict(x)</span><br><span class="line">    <span class="comment"># 绘制不同簇的点</span></span><br><span class="line">    plt.scatter(x[y_km == <span class="number">0</span>, <span class="number">0</span>], x[y_km == <span class="number">0</span>, <span class="number">1</span>], s=<span class="number">50</span>, c=<span class="string">&#x27;orange&#x27;</span>, marker=<span class="string">&#x27;o&#x27;</span>, label=<span class="string">&#x27;cluster 1&#x27;</span>,alpha=<span class="number">.3</span>)</span><br><span class="line">    plt.scatter(x[y_km == <span class="number">1</span>, <span class="number">0</span>], x[y_km == <span class="number">1</span>, <span class="number">1</span>], s=<span class="number">50</span>, c=<span class="string">&#x27;green&#x27;</span>, marker=<span class="string">&#x27;s&#x27;</span>, label=<span class="string">&#x27;cluster 2&#x27;</span>,alpha=<span class="number">.3</span>)</span><br><span class="line">    plt.scatter(x[y_km == <span class="number">2</span>, <span class="number">0</span>], x[y_km == <span class="number">2</span>, <span class="number">1</span>], s=<span class="number">50</span>, c=<span class="string">&#x27;blue&#x27;</span>, marker=<span class="string">&#x27;^&#x27;</span>, label=<span class="string">&#x27;cluster 3&#x27;</span>,alpha=<span class="number">.3</span>)</span><br><span class="line">    <span class="comment"># 绘制簇的中心点</span></span><br><span class="line">    plt.scatter(km.cluster_centers_[:, <span class="number">0</span>], km.cluster_centers_[:, <span class="number">1</span>], s=<span class="number">250</span>, marker=<span class="string">&quot;+&quot;</span>, c=<span class="string">&quot;k&quot;</span>,</span><br><span class="line">                label=<span class="string">&quot;cluster center&quot;</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.grid()</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>


    </div>

    
    
    

    <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/ML/" rel="tag"><i class="fa fa-tag"></i> ML</a>
              <a href="/tags/%E6%97%A0%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/" rel="tag"><i class="fa fa-tag"></i> 无监督学习</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2020/11/10/daily/" rel="prev" title="daily">
                  <i class="fa fa-chevron-left"></i> daily
                </a>
            </div>
            <div class="post-nav-item">
            </div>
          </div>
    </footer>
  </article>
</div>






      

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      const activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      const commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

    </div>
  </main>

  <footer class="footer">
    <div class="footer-inner">
      

      

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">KnightPanda</span>
</div>

    </div>
  </footer>

  
  <script src="//cdn.jsdelivr.net/npm/animejs@3.2.1/lib/anime.min.js"></script>
<script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script>

  













<script>
if (document.querySelectorAll('.mermaid').length) {
  NexT.utils.getScript('//cdn.jsdelivr.net/npm/mermaid@8.8.2/dist/mermaid.min.js', () => {
    mermaid.init({
      theme    : 'neutral',
      logLevel : 3,
      flowchart: { curve     : 'linear' },
      gantt    : { axisFormat: '%m/%d/%Y' },
      sequence : { actorMargin: 50 }
    }, '.mermaid');
  }, window.mermaid);
}
</script>



  <script>
    NProgress.configure({
      showSpinner: true
    });
    NProgress.start();
    document.addEventListener('readystatechange', () => {
      if (document.readyState === 'interactive') {
        NProgress.inc(0.8);
      }
      if (document.readyState === 'complete') {
        NProgress.done();
      }
    });
    document.addEventListener('pjax:send', () => {
      NProgress.start();
    });
    document.addEventListener('pjax:success', () => {
      NProgress.done();
    });
  </script>


  








  

  

</body>
</html>
